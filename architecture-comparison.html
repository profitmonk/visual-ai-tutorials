<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Architecture Comparison: Modern LLM Designs</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);
            color: #e0e0e0;
            line-height: 1.6;
        }
        
        .container {
            background: #ffffff;
            color: #2d2d2d;
            border-radius: 20px;
            padding: 30px;
            margin: 20px 0;
            border: 1px solid #e0e0e0;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
        
        .nav-bar {
            background: #2d2d2d;
            color: white;
            padding: 15px 30px;
            border-radius: 15px;
            margin: 20px 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .nav-home {
            background: #ffffff;
            color: #2d2d2d;
            padding: 8px 16px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .nav-home:hover {
            background: #f8f9fa;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        
        .nav-title {
            font-size: 1.2em;
            font-weight: bold;
        }
        
        .step {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            padding: 20px;
            margin: 15px 0;
            border-radius: 15px;
            border-left: 4px solid #2d2d2d;
        }
        
        .example-box {
            background: #2d2d2d;
            color: #e0e0e0;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            border: 1px solid #4a4a4a;
        }
        
        .controls {
            display: flex;
            gap: 15px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        
        button {
            background: #2d2d2d;
            border: none;
            color: white;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        button:hover {
            background: #1a1a1a;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        
        input, select {
            padding: 8px 12px;
            border: 1px solid #dadce0;
            border-radius: 6px;
            background: #ffffff;
            color: #2d2d2d;
        }
        
        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            color: #856404;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .success {
            background: #d4edda;
            border-left: 4px solid #28a745;
            color: #155724;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .info {
            background: #d1ecf1;
            border-left: 4px solid #17a2b8;
            color: #0c5460;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        .danger {
            background: #f8d7da;
            border-left: 4px solid #dc3545;
            color: #721c24;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
            background: #ffffff;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            overflow: hidden;
        }
        
        th {
            background: #2d2d2d;
            color: white;
            padding: 12px;
            text-align: center;
            font-weight: bold;
        }
        
        td {
            padding: 12px;
            text-align: center;
            border-bottom: 1px solid #e9ecef;
        }
        
        .winner {
            background: #d4edda;
            font-weight: bold;
        }
        
        .moderate {
            background: #fff3cd;
        }
        
        .poor {
            background: #f8d7da;
        }
        
        .math-formula {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            font-family: 'Courier New', monospace;
            text-align: center;
            font-size: 14px;
        }
        
        .architecture-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .arch-card {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 12px;
            padding: 20px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .arch-card:hover {
            border-color: #2d2d2d;
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
        }
        
        .arch-card.selected {
            border-color: #28a745;
            background: #d4edda;
        }
        
        .arch-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
            color: #2d2d2d;
        }
        
        .arch-specs {
            background: #2d2d2d;
            color: #e0e0e0;
            padding: 10px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            margin-top: 10px;
        }
        
        .innovation-badge {
            background: #dc3545;
            color: white;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 10px;
            font-weight: bold;
            margin: 2px;
            display: inline-block;
        }
        
        .efficiency-badge {
            background: #28a745;
            color: white;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 10px;
            font-weight: bold;
            margin: 2px;
            display: inline-block;
        }
        
        .comparison-matrix {
            overflow-x: auto;
            margin: 20px 0;
        }
        
        .feature-comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        
        .feature-card {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 12px;
            padding: 20px;
        }
        
        .feature-title {
            font-size: 1.1em;
            font-weight: bold;
            margin-bottom: 15px;
            color: #2d2d2d;
        }
        
        .vs-divider {
            text-align: center;
            font-size: 2em;
            font-weight: bold;
            color: #dc3545;
            margin: 20px 0;
        }
        
        .timeline {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 12px;
            border: 2px solid #e9ecef;
        }
        
        .timeline-item {
            text-align: center;
            flex: 1;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        .timeline-item:hover {
            transform: scale(1.1);
        }
        
        .timeline-date {
            background: #2d2d2d;
            color: white;
            padding: 6px 12px;
            border-radius: 15px;
            font-weight: bold;
            margin-bottom: 8px;
            display: inline-block;
            font-size: 12px;
        }
        
        .timeline-model {
            font-weight: bold;
            color: #2d2d2d;
            margin-bottom: 5px;
            font-size: 14px;
        }
        
        .timeline-innovation {
            font-size: 11px;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="nav-bar">
        <div class="nav-title">üìä Architecture Comparison: Modern LLM Designs</div>
        <a href="index.html" class="nav-home">üè† Home</a>
    </div>

    <div class="container">
        <h1>üìä Modern LLM Architecture Comparison</h1>
        <p>Comprehensive analysis of production LLM architectures from industry leaders - understanding design decisions, trade-offs, and innovations that shape 2025's AI landscape</p>
        
        <div class="info">
            <strong>üéØ Based on Sebastian Raschka's research:</strong> This tutorial analyzes real production architectures from DeepSeek, Meta, Google, Mistral, Alibaba, and more - focusing on the architectural innovations that make modern LLMs work.
        </div>
    </div>

    <div class="container">
        <h2>üï∞Ô∏è The Architecture Evolution Timeline</h2>
        
        <div class="timeline">
            <div class="timeline-item" onclick="showEvolution('deepseek')">
                <div class="timeline-date">Dec 2024</div>
                <div class="timeline-model">DeepSeek V3</div>
                <div class="timeline-innovation">MLA + MoE Revolution</div>
            </div>
            <div class="timeline-item" onclick="showEvolution('olmo')">
                <div class="timeline-date">Jan 2025</div>
                <div class="timeline-model">OLMo 2</div>
                <div class="timeline-innovation">Post-Norm + QK-Norm</div>
            </div>
            <div class="timeline-item" onclick="showEvolution('gemma')">
                <div class="timeline-date">Feb 2025</div>
                <div class="timeline-model">Gemma 3</div>
                <div class="timeline-innovation">Sliding Window 5:1</div>
            </div>
            <div class="timeline-item" onclick="showEvolution('llama')">
                <div class="timeline-date">Mar 2025</div>
                <div class="timeline-model">Llama 4</div>
                <div class="timeline-innovation">Alternating MoE</div>
            </div>
            <div class="timeline-item" onclick="showEvolution('kimi')">
                <div class="timeline-date">May 2025</div>
                <div class="timeline-model">Kimi K2</div>
                <div class="timeline-innovation">1T Parameters</div>
            </div>
        </div>
        
        <div id="evolutionDetails"></div>
    </div>

    <div class="container">
        <h2>üèóÔ∏è Interactive Architecture Explorer</h2>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Primary Model:</strong></label>
                <select id="primaryModel">
                    <option value="deepseek-v3" selected>DeepSeek V3 (671B)</option>
                    <option value="llama-4">Llama 4 Maverick (400B)</option>
                    <option value="gemma-3">Gemma 3 (27B)</option>
                    <option value="qwen3-235b">Qwen3 235B-A22B</option>
                    <option value="kimi-k2">Kimi K2 (1T)</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Comparison Model:</strong></label>
                <select id="comparisonModel">
                    <option value="llama-4" selected>Llama 4 Maverick (400B)</option>
                    <option value="deepseek-v3">DeepSeek V3 (671B)</option>
                    <option value="gemma-3">Gemma 3 (27B)</option>
                    <option value="qwen3-235b">Qwen3 235B-A22B</option>
                    <option value="olmo-2">OLMo 2 (13B)</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Focus Area:</strong></label>
                <select id="focusArea">
                    <option value="attention" selected>Attention Mechanisms</option>
                    <option value="efficiency">Efficiency Strategies</option>
                    <option value="scaling">Scaling Approaches</option>
                    <option value="normalization">Normalization Techniques</option>
                </select>
            </div>
        </div>
        
        <button onclick="compareArchitectures()">üîç Compare Architectures</button>
        <div id="architectureComparison"></div>
    </div>

    <div class="container">
        <h2>‚ö° DeepSeek V3 vs Llama 4: The MoE Showdown</h2>
        
        <div class="warning">
            <strong>üéØ Key Battle:</strong> Two of 2025's most important architectures take completely different approaches to Mixture of Experts and attention mechanisms.
        </div>
        
        <div class="feature-comparison">
            <div class="feature-card">
                <div class="feature-title">üß† DeepSeek V3 Strategy</div>
                <div class="innovation-badge">MLA</div>
                <div class="efficiency-badge">Dense MoE</div>
                <div class="efficiency-badge">Shared Expert</div>
                
                <div class="example-box">
                    <strong>Architecture Highlights:</strong><br>
                    ‚Ä¢ 671B total parameters, 37B active<br>
                    ‚Ä¢ Multi-Head Latent Attention (MLA)<br>
                    ‚Ä¢ 256 experts, 9 active (8 + 1 shared)<br>
                    ‚Ä¢ MoE in every layer (except first 3)<br>
                    ‚Ä¢ Compressed KV cache via MLA<br>
                    ‚Ä¢ Expert size: 2,048 hidden units
                </div>
                
                <div class="math-formula">
                    <strong>MLA Compression:</strong><br>
                    K, V ‚Üí compress ‚Üí KV cache ‚Üí decompress ‚Üí attention<br>
                    Memory savings: ~50% vs standard GQA
                </div>
            </div>
            
            <div class="feature-card">
                <div class="feature-title">üöÄ Llama 4 Strategy</div>
                <div class="innovation-badge">GQA</div>
                <div class="efficiency-badge">Sparse MoE</div>
                <div class="efficiency-badge">Alternating</div>
                
                <div class="example-box">
                    <strong>Architecture Highlights:</strong><br>
                    ‚Ä¢ 400B total parameters, 17B active<br>
                    ‚Ä¢ Grouped Query Attention (GQA)<br>
                    ‚Ä¢ Fewer experts, 2 active per token<br>
                    ‚Ä¢ Alternates MoE/dense every other layer<br>
                    ‚Ä¢ Standard KV cache approach<br>
                    ‚Ä¢ Expert size: 8,192 hidden units
                </div>
                
                <div class="math-formula">
                    <strong>Alternating MoE:</strong><br>
                    Layer 1: Dense ‚Üí Layer 2: MoE ‚Üí Layer 3: Dense...<br>
                    Fewer active params but larger experts
                </div>
            </div>
        </div>
        
        <div class="vs-divider">VS</div>
        
        <div class="step">
            <h3>üìä Head-to-Head Analysis</h3>
            
            <div class="comparison-matrix">
                <table>
                    <tr>
                        <th>Aspect</th>
                        <th>DeepSeek V3</th>
                        <th>Llama 4 Maverick</th>
                        <th>Winner</th>
                    </tr>
                    <tr>
                        <td><strong>Total Parameters</strong></td>
                        <td>671B</td>
                        <td>400B</td>
                        <td class="winner">DeepSeek (Capacity)</td>
                    </tr>
                    <tr>
                        <td><strong>Active Parameters</strong></td>
                        <td>37B</td>
                        <td>17B</td>
                        <td class="winner">DeepSeek (More Active)</td>
                    </tr>
                    <tr>
                        <td><strong>Attention Type</strong></td>
                        <td>MLA (compressed)</td>
                        <td>GQA (standard)</td>
                        <td class="moderate">Trade-off</td>
                    </tr>
                    <tr>
                        <td><strong>MoE Strategy</strong></td>
                        <td>Dense (every layer)</td>
                        <td>Sparse (alternating)</td>
                        <td class="moderate">Different approaches</td>
                    </tr>
                    <tr>
                        <td><strong>KV Cache Memory</strong></td>
                        <td class="winner">~50% savings (MLA)</td>
                        <td>Standard usage</td>
                        <td class="winner">DeepSeek</td>
                    </tr>
                    <tr>
                        <td><strong>Implementation</strong></td>
                        <td class="poor">Complex (MLA)</td>
                        <td class="winner">Simpler (GQA)</td>
                        <td class="winner">Llama 4</td>
                    </tr>
                </table>
            </div>
            
            <div class="success">
                <strong>üèÜ Key Insight:</strong> DeepSeek V3 optimizes for maximum capability and memory efficiency through MLA, while Llama 4 balances performance with implementation simplicity through proven GQA + alternating MoE.
            </div>
        </div>
        
        <button onclick="showDetailedMoEComparison()">üî¨ Deep Dive: MoE Implementation Details</button>
        <div id="moeDetails"></div>
    </div>

    <div class="container">
        <h2>üéØ Architecture Selection Guide</h2>
        
        <div class="step">
            <h3>ü§î Which Architecture for Which Use Case?</h3>
            
            <div class="architecture-grid">
                <div class="arch-card" onclick="selectUseCase('research')">
                    <div class="arch-title">üî¨ Research & Experimentation</div>
                    <div>Best: OLMo 2, SmolLM3</div>
                    <div class="innovation-badge">Transparent</div>
                    <div class="innovation-badge">Well-documented</div>
                    <div class="arch-specs">
                        ‚Ä¢ Full training details available<br>
                        ‚Ä¢ Clean, standard architectures<br>
                        ‚Ä¢ Educational focus
                    </div>
                </div>
                
                <div class="arch-card" onclick="selectUseCase('production')">
                    <div class="arch-title">üè≠ Production Deployment</div>
                    <div>Best: Llama 4, Gemma 3</div>
                    <div class="efficiency-badge">Proven</div>
                    <div class="efficiency-badge">Optimized</div>
                    <div class="arch-specs">
                        ‚Ä¢ Battle-tested architectures<br>
                        ‚Ä¢ Extensive optimization<br>
                        ‚Ä¢ Ecosystem support
                    </div>
                </div>
                
                <div class="arch-card" onclick="selectUseCase('efficiency')">
                    <div class="arch-title">‚ö° Maximum Efficiency</div>
                    <div>Best: DeepSeek V3, Qwen3</div>
                    <div class="efficiency-badge">MLA/MoE</div>
                    <div class="efficiency-badge">Memory-efficient</div>
                    <div class="arch-specs">
                        ‚Ä¢ Cutting-edge optimizations<br>
                        ‚Ä¢ Lowest inference cost<br>
                        ‚Ä¢ Advanced techniques
                    </div>
                </div>
                
                <div class="arch-card" onclick="selectUseCase('local')">
                    <div class="arch-title">üíª Local Deployment</div>
                    <div>Best: Gemma 3, Qwen3 small</div>
                    <div class="efficiency-badge">Sliding Window</div>
                    <div class="efficiency-badge">Small variants</div>
                    <div class="arch-specs">
                        ‚Ä¢ Reduced memory usage<br>
                        ‚Ä¢ Consumer hardware friendly<br>
                        ‚Ä¢ Multiple size options
                    </div>
                </div>
            </div>
            
            <div id="useCaseDetails"></div>
        </div>
    </div>

    <div class="container">
        <h2>üéØ Attention Evolution Deep Dive</h2>
        
        <div class="info">
            <strong>üß† The Attention Revolution:</strong> From Multi-Head Attention to compressed representations - how modern LLMs optimize the memory bottleneck.
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Attention Type:</strong></label>
                <select id="attentionType">
                    <option value="mha">Multi-Head Attention (MHA)</option>
                    <option value="gqa" selected>Grouped Query Attention (GQA)</option>
                    <option value="mla">Multi-Head Latent Attention (MLA)</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Model Size:</strong></label>
                <select id="modelSize">
                    <option value="7B" selected>7B Parameters</option>
                    <option value="13B">13B Parameters</option>
                    <option value="70B">70B Parameters</option>
                    <option value="405B">405B Parameters</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Sequence Length:</strong></label>
                <input type="range" id="seqLength" min="1024" max="32768" value="8192" step="1024">
                <span id="seqLengthValue">8192</span> tokens
            </div>
        </div>
        
        <button onclick="calculateAttentionMetrics()">üßÆ Calculate Memory Usage</button>
        <div id="attentionAnalysis"></div>
        
        <div class="step">
            <h3>üìä Attention Mechanism Comparison</h3>
            
            <div class="feature-comparison">
                <div class="feature-card">
                    <div class="feature-title">üîπ Multi-Head Attention (MHA)</div>
                    <div class="innovation-badge">Original</div>
                    <div class="arch-specs">
                        Used by: Original Transformers, GPT-1/2<br>
                        Heads: All independent K,V,Q<br>
                        Memory: Highest (full KV cache)<br>
                        Quality: Baseline performance
                    </div>
                    <div class="math-formula">
                        <strong>MHA Formula:</strong><br>
                        heads = n_heads<br>
                        KV_cache = 2 √ó seq_len √ó n_heads √ó head_dim<br>
                        Each head: independent K, V matrices
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-title">üî∏ Grouped Query Attention (GQA)</div>
                    <div class="efficiency-badge">Proven</div>
                    <div class="arch-specs">
                        Used by: Llama 2/3/4, GPT-4, Gemma<br>
                        Heads: Shared K,V across groups<br>
                        Memory: ~4x reduction vs MHA<br>
                        Quality: 99% of MHA performance
                    </div>
                    <div class="math-formula">
                        <strong>GQA Formula:</strong><br>
                        groups = n_heads // group_size<br>
                        KV_cache = 2 √ó seq_len √ó groups √ó head_dim<br>
                        Multiple Q heads share K,V pairs
                    </div>
                </div>
            </div>
            
            <div class="feature-comparison">
                <div class="feature-card">
                    <div class="feature-title">üî∫ Multi-Head Latent Attention (MLA)</div>
                    <div class="innovation-badge">Cutting-edge</div>
                    <div class="arch-specs">
                        Used by: DeepSeek V3, Kimi K2<br>
                        Heads: Compressed latent space<br>
                        Memory: ~50% of GQA usage<br>
                        Quality: Matches/exceeds GQA
                    </div>
                    <div class="math-formula">
                        <strong>MLA Formula:</strong><br>
                        compressed_kv = low_rank_projection(K,V)<br>
                        KV_cache = 2 √ó seq_len √ó compressed_dim<br>
                        At inference: decompress ‚Üí attention
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-title">üî≤ Sliding Window Attention</div>
                    <div class="efficiency-badge">Local-efficient</div>
                    <div class="arch-specs">
                        Used by: Gemma 3, Mistral, Longformer<br>
                        Pattern: Local + sparse global<br>
                        Memory: Linear in window size<br>
                        Quality: Great for local patterns
                    </div>
                    <div class="math-formula">
                        <strong>Sliding Window:</strong><br>
                        window_size = 1024 (Gemma 3)<br>
                        KV_cache = 2 √ó window_size √ó n_heads √ó head_dim<br>
                        Constant memory regardless of sequence
                    </div>
                </div>
            </div>
        </div>
        
        <div class="step">
            <h3>üî¨ Real Model Examples</h3>
            
            <div class="comparison-matrix">
                <table>
                    <tr>
                        <th>Model</th>
                        <th>Attention Type</th>
                        <th>Heads Config</th>
                        <th>KV Cache (8K seq)</th>
                        <th>Innovation</th>
                    </tr>
                    <tr>
                        <td><strong>GPT-4</strong></td>
                        <td>GQA</td>
                        <td>128 Q heads, 8 KV heads</td>
                        <td class="moderate">~16x compression</td>
                        <td>Production-proven</td>
                    </tr>
                    <tr>
                        <td><strong>Llama 4</strong></td>
                        <td>GQA</td>
                        <td>64 Q heads, 8 KV heads</td>
                        <td class="moderate">~8x compression</td>
                        <td>Balanced efficiency</td>
                    </tr>
                    <tr>
                        <td><strong>DeepSeek V3</strong></td>
                        <td>MLA</td>
                        <td>Compressed to 1024 dims</td>
                        <td class="winner">~50x compression</td>
                        <td>Memory breakthrough</td>
                    </tr>
                    <tr>
                        <td><strong>Gemma 3</strong></td>
                        <td>Sliding GQA</td>
                        <td>16 Q heads, 4 KV, 1K window</td>
                        <td class="winner">Constant memory</td>
                        <td>Local efficiency</td>
                    </tr>
                </table>
            </div>
        </div>
    </div>

    <div class="container">
        <h2>üìä Normalization Strategy Analysis</h2>
        
        <div class="warning">
            <strong>üéØ Normalization Wars:</strong> The placement and type of normalization layers dramatically impacts training stability and final performance.
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Normalization Strategy:</strong></label>
                <select id="normStrategy" onchange="showNormStrategy()">
                    <option value="pre-norm" selected>Pre-Norm (Llama style)</option>
                    <option value="post-norm">Post-Norm (Original Transformer)</option>
                    <option value="qk-norm">QK-Norm (OLMo 2)</option>
                    <option value="dual-norm">Pre+Post (Gemma 3)</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Training Phase:</strong></label>
                <select id="trainingPhase">
                    <option value="early">Early Training</option>
                    <option value="middle" selected>Mid Training</option>
                    <option value="late">Late Training</option>
                </select>
            </div>
        </div>
        
        <button onclick="analyzeNormalization()">üìà Analyze Gradient Flow</button>
        <div id="normalizationAnalysis"></div>
        
        <div class="step">
            <h3>üèóÔ∏è Transformer Block Architectures</h3>
            
            <div class="architecture-grid">
                <div class="arch-card" onclick="selectNormType('pre-norm')">
                    <div class="arch-title">üîµ Pre-Norm (Modern)</div>
                    <div class="efficiency-badge">Stable</div>
                    <div class="arch-specs">
                        Used by: Llama, GPT-3+, Gemma<br>
                        Pattern: Norm ‚Üí Attention ‚Üí Add<br>
                        Benefits: Training stability<br>
                        Drawback: Slightly lower performance
                    </div>
                    <div class="example-box">
                        x = x + attention(norm(x))<br>
                        x = x + ffn(norm(x))
                    </div>
                </div>
                
                <div class="arch-card" onclick="selectNormType('post-norm')">
                    <div class="arch-title">üü¢ Post-Norm (Classic)</div>
                    <div class="innovation-badge">Original</div>
                    <div class="arch-specs">
                        Used by: Original Transformer, OLMo 2<br>
                        Pattern: Attention ‚Üí Add ‚Üí Norm<br>
                        Benefits: Better final performance<br>
                        Drawback: Training instability
                    </div>
                    <div class="example-box">
                        x = norm(x + attention(x))<br>
                        x = norm(x + ffn(x))
                    </div>
                </div>
                
                <div class="arch-card" onclick="selectNormType('qk-norm')">
                    <div class="arch-title">üü° QK-Norm (OLMo 2)</div>
                    <div class="efficiency-badge">Innovative</div>
                    <div class="arch-specs">
                        Used by: OLMo 2, some research models<br>
                        Pattern: Normalize inside attention<br>
                        Benefits: Attention stability<br>
                        Innovation: Prevents attention collapse
                    </div>
                    <div class="example-box">
                        Q = norm_q(query_proj(x))<br>
                        K = norm_k(key_proj(x))<br>
                        attention(Q, K, V)
                    </div>
                </div>
                
                <div class="arch-card" onclick="selectNormType('dual-norm')">
                    <div class="arch-title">üü£ Pre+Post (Gemma 3)</div>
                    <div class="innovation-badge">Hybrid</div>
                    <div class="arch-specs">
                        Used by: Gemma 3<br>
                        Pattern: Both normalizations<br>
                        Benefits: Best of both worlds<br>
                        Cost: Extra computation
                    </div>
                    <div class="example-box">
                        x = norm_post(x + attention(norm_pre(x)))<br>
                        x = norm_post(x + ffn(norm_pre(x)))
                    </div>
                </div>
            </div>
            
            <div id="normTypeDetails"></div>
        </div>
        
        <div class="step">
            <h3>üìä Training Stability Analysis</h3>
            
            <div class="comparison-matrix">
                <table>
                    <tr>
                        <th>Strategy</th>
                        <th>Training Stability</th>
                        <th>Final Performance</th>
                        <th>Implementation</th>
                        <th>Used By</th>
                    </tr>
                    <tr>
                        <td><strong>Pre-Norm</strong></td>
                        <td class="winner">Excellent</td>
                        <td class="moderate">Good</td>
                        <td class="winner">Simple</td>
                        <td>Llama, GPT-3+</td>
                    </tr>
                    <tr>
                        <td><strong>Post-Norm</strong></td>
                        <td class="poor">Challenging</td>
                        <td class="winner">Best</td>
                        <td class="winner">Simple</td>
                        <td>Original, OLMo 2</td>
                    </tr>
                    <tr>
                        <td><strong>QK-Norm</strong></td>
                        <td class="winner">Excellent</td>
                        <td class="moderate">Good</td>
                        <td class="moderate">Moderate</td>
                        <td>OLMo 2</td>
                    </tr>
                    <tr>
                        <td><strong>Pre+Post</strong></td>
                        <td class="winner">Excellent</td>
                        <td class="winner">Excellent</td>
                        <td class="poor">Complex</td>
                        <td>Gemma 3</td>
                    </tr>
                </table>
            </div>
        </div>
    </div>

    <div class="container">
        <h2>üîÑ Complete Model Architecture Showcase</h2>
        
        <div class="info">
            <strong>üéØ 2025's Leading Architectures:</strong> Deep dive into each model's unique innovations and design philosophy.
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Model Focus:</strong></label>
                <select id="modelFocus" onchange="showModelDetails()">
                    <option value="olmo-2" selected>OLMo 2 - Transparency Leader</option>
                    <option value="gemma-3">Gemma 3 - Sliding Window Master</option>
                    <option value="qwen3">Qwen3 - Dense+MoE Strategy</option>
                    <option value="mistral-small">Mistral Small 3.1 - Efficiency Focus</option>
                    <option value="smollm3">SmolLM3 - NoPE Innovation</option>
                    <option value="kimi-k2">Kimi K2 - Trillion Parameter Scale</option>
                </select>
            </div>
        </div>
        
        <div id="modelDetailsContainer"></div>
        
        <div class="step">
            <h3>üèÜ Architecture Innovation Leaderboard</h3>
            
            <div class="comparison-matrix">
                <table>
                    <tr>
                        <th>Innovation</th>
                        <th>Pioneer Model</th>
                        <th>Impact</th>
                        <th>Adoption</th>
                        <th>Future</th>
                    </tr>
                    <tr>
                        <td><strong>MLA Compression</strong></td>
                        <td class="winner">DeepSeek V3</td>
                        <td>üî• Game-changing</td>
                        <td>Early adoption</td>
                        <td>Industry standard</td>
                    </tr>
                    <tr>
                        <td><strong>Sliding Window 5:1</strong></td>
                        <td class="winner">Gemma 3</td>
                        <td>üî• Memory breakthrough</td>
                        <td>Growing fast</td>
                        <td>Local model standard</td>
                    </tr>
                    <tr>
                        <td><strong>Post-Norm Return</strong></td>
                        <td class="moderate">OLMo 2</td>
                        <td>üìà Performance boost</td>
                        <td>Research interest</td>
                        <td>Specialized use</td>
                    </tr>
                    <tr>
                        <td><strong>No Positional Embedding</strong></td>
                        <td class="moderate">SmolLM3</td>
                        <td>üìà Simplification</td>
                        <td>Experimental</td>
                        <td>Small model trend</td>
                    </tr>
                    <tr>
                        <td><strong>Alternating MoE</strong></td>
                        <td class="winner">Llama 4</td>
                        <td>üî• Balanced scaling</td>
                        <td>Production proven</td>
                        <td>MoE standard</td>
                    </tr>
                </table>
            </div>
        </div>
    </div>

    <div class="container">
        <h2>‚ö° Efficiency Innovations Deep Dive</h2>
        
        <div class="success">
            <strong>üí° The Efficiency Revolution:</strong> Modern LLMs achieve better performance with fewer resources through architectural innovations.
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Efficiency Technique:</strong></label>
                <select id="efficiencyTech" onchange="showEfficiencyDetails()">
                    <option value="sliding-window" selected>Sliding Window Attention</option>
                    <option value="nope">No Positional Embeddings (NoPE)</option>
                    <option value="mla-compression">MLA KV Compression</option>
                    <option value="memory-optimizations">Memory Optimizations</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Model Size:</strong></label>
                <input type="range" id="efficiencySize" min="1" max="1000" value="70" step="1">
                <span id="efficiencySizeValue">70</span>B parameters
            </div>
            <div class="control-group">
                <label><strong>Sequence Length:</strong></label>
                <input type="range" id="efficiencySeq" min="1024" max="131072" value="8192" step="1024">
                <span id="efficiencySeqValue">8192</span> tokens
            </div>
        </div>
        
        <button onclick="calculateEfficiency()">‚ö° Calculate Efficiency Gains</button>
        <div id="efficiencyCalculator"></div>
        
        <div class="step">
            <h3>üéØ Sliding Window Mastery: Gemma 3's Innovation</h3>
            
            <div class="feature-comparison">
                <div class="feature-card">
                    <div class="feature-title">üîÑ Traditional Attention</div>
                    <div class="poor">Quadratic Memory</div>
                    <div class="math-formula">
                        <strong>Full Attention:</strong><br>
                        Memory = O(seq_len¬≤)<br>
                        For 32K: 1B attention ops<br>
                        KV Cache: Linear growth<br>
                        Problem: Unsustainable scaling
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-title">ü™ü Sliding Window (Gemma 3)</div>
                    <div class="winner">Linear Memory</div>
                    <div class="math-formula">
                        <strong>5:1 Window Strategy:</strong><br>
                        Window: 1024 tokens (vs 4096)<br>
                        Memory = O(window_size)<br>
                        For any seq: 1M attention ops<br>
                        Result: 75% memory reduction
                    </div>
                </div>
            </div>
            
            <div class="warning">
                <strong>üéØ Gemma 3 Innovation:</strong> Revolutionary 5:1 compression ratio - reduced window from 4K to 1K tokens while maintaining 99% performance. This enables running 27B parameter models on consumer hardware.
            </div>
        </div>
        
        <div class="step">
            <h3>üö´ NoPE Revolution: SmolLM3's Position-Free Future</h3>
            
            <div class="feature-comparison">
                <div class="feature-card">
                    <div class="feature-title">üìç Traditional Positioning</div>
                    <div class="moderate">RoPE/Absolute</div>
                    <div class="example-box">
                        <strong>Standard Approach:</strong><br>
                        ‚Ä¢ Absolute positions (GPT)<br>
                        ‚Ä¢ RoPE rotations (Llama)<br>
                        ‚Ä¢ Learned embeddings<br>
                        ‚Ä¢ ALiBi relative bias<br>
                        ‚Üí Extra parameters & computation
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-title">üö´ No Positional Embeddings</div>
                    <div class="efficiency-badge">Zero Position</div>
                    <div class="example-box">
                        <strong>NoPE Approach:</strong><br>
                        ‚Ä¢ No position information<br>
                        ‚Ä¢ Pure content-based attention<br>
                        ‚Ä¢ Causal masking only<br>
                        ‚Ä¢ 15-20% parameter reduction<br>
                        ‚Üí Simpler, more efficient
                    </div>
                </div>
            </div>
            
            <div class="info">
                <strong>üí° NoPE Benefits:</strong> SmolLM3 proves that small models don't need positional embeddings. The causal attention mask provides sufficient ordering information, reducing parameters and simplifying architecture.
            </div>
        </div>
    </div>

    <div class="container">
        <h2>üéÆ Interactive Architecture Builder</h2>
        
        <div class="danger">
            <strong>üõ†Ô∏è Build Your LLM:</strong> Mix and match components from leading architectures to design your optimal model.
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Base Architecture:</strong></label>
                <select id="baseArch">
                    <option value="transformer" selected>Standard Transformer</option>
                    <option value="llama">Llama-style (RMSNorm + RoPE)</option>
                    <option value="deepseek">DeepSeek-style (MLA + MoE)</option>
                    <option value="gemma">Gemma-style (Sliding + Dual-norm)</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Attention Type:</strong></label>
                <select id="builderAttention">
                    <option value="mha">Multi-Head Attention</option>
                    <option value="gqa" selected>Grouped Query Attention</option>
                    <option value="mla">Multi-Head Latent Attention</option>
                    <option value="sliding">Sliding Window</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Normalization:</strong></label>
                <select id="builderNorm">
                    <option value="pre-norm" selected>Pre-Norm</option>
                    <option value="post-norm">Post-Norm</option>
                    <option value="qk-norm">QK-Norm</option>
                    <option value="dual-norm">Pre+Post</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>FFN Strategy:</strong></label>
                <select id="builderFFN">
                    <option value="dense" selected>Dense FFN</option>
                    <option value="moe">Mixture of Experts</option>
                    <option value="alternating">Alternating Dense/MoE</option>
                </select>
            </div>
            <div class="control-group">
                <label><strong>Position Encoding:</strong></label>
                <select id="builderPosition">
                    <option value="rope" selected>RoPE</option>
                    <option value="absolute">Absolute</option>
                    <option value="alibi">ALiBi</option>
                    <option value="nope">NoPE (None)</option>
                </select>
            </div>
        </div>
        
        <div class="controls">
            <div class="control-group">
                <label><strong>Model Size:</strong></label>
                <input type="range" id="builderSize" min="1" max="1000" value="70" step="1">
                <span id="builderSizeValue">70</span>B parameters
            </div>
            <div class="control-group">
                <label><strong>Target Use Case:</strong></label>
                <select id="builderUseCase">
                    <option value="general" selected>General Purpose</option>
                    <option value="code">Code Generation</option>
                    <option value="research">Research/Science</option>
                    <option value="chat">Chat/Assistant</option>
                    <option value="local">Local Deployment</option>
                </select>
            </div>
        </div>
        
        <button onclick="buildArchitecture()">üèóÔ∏è Build Architecture</button>
        <button onclick="analyzeTradeoffs()">‚öñÔ∏è Analyze Trade-offs</button>
        <div id="architectureBuilder"></div>
        
        <div class="step">
            <h3>üéØ Architecture Recommendation Engine</h3>
            <div id="recommendationEngine"></div>
        </div>
    </div>

    <div class="container">
        <h2>üî¨ Performance Analysis & Deployment Guide</h2>
        
        <div class="info">
            <strong>üìä Real-World Performance:</strong> Comprehensive analysis of memory usage, inference speed, and deployment considerations.
        </div>
        
        <div class="step">
            <h3>üíæ Memory Usage Comparison</h3>
            
            <div class="comparison-matrix">
                <table>
                    <tr>
                        <th>Model</th>
                        <th>Parameters</th>
                        <th>KV Cache (8K)</th>
                        <th>Total Memory</th>
                        <th>Efficiency Score</th>
                    </tr>
                    <tr>
                        <td><strong>DeepSeek V3</strong></td>
                        <td>671B (37B active)</td>
                        <td class="winner">12GB (MLA)</td>
                        <td>~180GB</td>
                        <td class="winner">A+</td>
                    </tr>
                    <tr>
                        <td><strong>Llama 4</strong></td>
                        <td>400B (17B active)</td>
                        <td class="moderate">24GB (GQA)</td>
                        <td>~120GB</td>
                        <td class="winner">A</td>
                    </tr>
                    <tr>
                        <td><strong>Gemma 3</strong></td>
                        <td>27B (dense)</td>
                        <td class="winner">8GB (sliding)</td>
                        <td>54GB</td>
                        <td class="winner">A+</td>
                    </tr>
                    <tr>
                        <td><strong>Qwen3 235B</strong></td>
                        <td>235B (22B active)</td>
                        <td class="moderate">20GB (GQA)</td>
                        <td>~100GB</td>
                        <td class="moderate">B+</td>
                    </tr>
                </table>
            </div>
        </div>
        
        <div class="step">
            <h3>üöÄ Deployment Recommendations</h3>
            
            <div class="architecture-grid">
                <div class="arch-card">
                    <div class="arch-title">‚òÅÔ∏è Cloud Deployment</div>
                    <div class="efficiency-badge">Scalable</div>
                    <div class="arch-specs">
                        Best: DeepSeek V3, Llama 4<br>
                        Hardware: 8xH100, A100<br>
                        Benefits: Full capability<br>
                        Cost: $2-5/hour
                    </div>
                </div>
                
                <div class="arch-card">
                    <div class="arch-title">üè¢ Enterprise On-Prem</div>
                    <div class="efficiency-badge">Secure</div>
                    <div class="arch-specs">
                        Best: Gemma 3, Qwen3<br>
                        Hardware: 4xA6000, 4090<br>
                        Benefits: Privacy control<br>
                        Investment: $50-200K
                    </div>
                </div>
                
                <div class="arch-card">
                    <div class="arch-title">üíª Developer Local</div>
                    <div class="efficiency-badge">Accessible</div>
                    <div class="arch-specs">
                        Best: SmolLM3, Gemma 3 small<br>
                        Hardware: RTX 4090, M3 Max<br>
                        Benefits: Instant iteration<br>
                        Cost: $1-5K hardware
                    </div>
                </div>
                
                <div class="arch-card">
                    <div class="arch-title">üì± Edge Deployment</div>
                    <div class="efficiency-badge">Efficient</div>
                    <div class="arch-specs">
                        Best: Quantized Gemma 3<br>
                        Hardware: Mobile GPU, NPU<br>
                        Benefits: Zero latency<br>
                        Constraints: Limited capability
                    </div>
                </div>
            </div>
        </div>
        
        <div class="success">
            <strong>üéØ Key Takeaway:</strong> 2025's architectural innovations make powerful AI accessible across deployment scenarios - from trillion-parameter cloud models to efficient edge deployment.
        </div>
    </div>

    <script>
        // Model specifications database
        const modelSpecs = {
            'deepseek-v3': {
                name: 'DeepSeek V3',
                totalParams: '671B',
                activeParams: '37B',
                attention: 'Multi-Head Latent Attention (MLA)',
                moe: 'Dense MoE (256 experts, 9 active)',
                innovations: ['MLA compression', 'Shared expert', 'KV cache optimization'],
                released: 'December 2024',
                company: 'DeepSeek',
                keyFeature: 'Memory-efficient MLA with massive MoE'
            },
            'llama-4': {
                name: 'Llama 4 Maverick',
                totalParams: '400B',
                activeParams: '17B',
                attention: 'Grouped Query Attention (GQA)',
                moe: 'Alternating MoE (2 active experts)',
                innovations: ['Alternating dense/MoE', 'Large expert size', 'Simplified routing'],
                released: 'March 2025',
                company: 'Meta',
                keyFeature: 'Balanced MoE with proven GQA'
            },
            'gemma-3': {
                name: 'Gemma 3',
                totalParams: '27B',
                activeParams: '27B (dense)',
                attention: 'Sliding Window GQA',
                moe: 'No MoE (dense model)',
                innovations: ['5:1 sliding window', 'Pre+Post norm', 'QK normalization'],
                released: 'February 2025',
                company: 'Google',
                keyFeature: 'Sliding window attention efficiency'
            },
            'qwen3-235b': {
                name: 'Qwen3 235B-A22B',
                totalParams: '235B',
                activeParams: '22B',
                attention: 'Grouped Query Attention (GQA)',
                moe: 'Standard MoE (8 active experts)',
                innovations: ['No shared expert', 'Optimized routing', 'Multi-size variants'],
                released: 'April 2025',
                company: 'Alibaba',
                keyFeature: 'Efficient MoE without shared expert'
            },
            'olmo-2': {
                name: 'OLMo 2',
                totalParams: '13B',
                activeParams: '13B (dense)',
                attention: 'Multi-Head Attention (MHA)',
                moe: 'No MoE (dense model)',
                innovations: ['Post-norm placement', 'QK normalization', 'Training transparency'],
                released: 'January 2025',
                company: 'Allen Institute',
                keyFeature: 'Transparent training with norm innovations'
            },
            'kimi-k2': {
                name: 'Kimi K2',
                totalParams: '1T',
                activeParams: '~100B',
                attention: 'Multi-Head Latent Attention (MLA)',
                moe: 'Massive MoE (like DeepSeek V3)',
                innovations: ['Trillion parameters', 'Muon optimizer', 'Scaled MLA'],
                released: 'May 2025',
                company: 'Moonshot AI',
                keyFeature: 'Largest open-weight model with MLA'
            }
        };

        function showEvolution(model) {
            let html = '<div class="step"><h3>üìà ' + model.toUpperCase() + ' Innovation Spotlight</h3>';
            
            switch(model) {
                case 'deepseek':
                    html += '<div class="example-box">';
                    html += '<strong>DeepSeek V3 Revolution (December 2024):</strong><br>';
                    html += '‚Ä¢ Introduced Multi-Head Latent Attention (MLA) to production<br>';
                    html += '‚Ä¢ Massive 671B parameters with only 37B active<br>';
                    html += '‚Ä¢ 50% KV cache memory savings vs standard GQA<br>';
                    html += '‚Ä¢ Shared expert design for better specialization<br>';
                    html += '‚Ä¢ Outperformed GPT-4 while being more efficient';
                    html += '</div>';
                    break;
                    
                case 'olmo':
                    html += '<div class="example-box">';
                    html += '<strong>OLMo 2 Transparency (January 2025):</strong><br>';
                    html += '‚Ä¢ Returned to Post-Norm for better training stability<br>';
                    html += '‚Ä¢ Added QK-Norm inside attention mechanism<br>';
                    html += '‚Ä¢ Full training transparency - code, data, logs<br>';
                    html += '‚Ä¢ Achieved Pareto frontier on compute/performance<br>';
                    html += '‚Ä¢ Educational blueprint for LLM development';
                    html += '</div>';
                    break;
                    
                case 'gemma':
                    html += '<div class="example-box">';
                    html += '<strong>Gemma 3 Efficiency (February 2025):</strong><br>';
                    html += '‚Ä¢ Revolutionary 5:1 sliding window ratio<br>';
                    html += '‚Ä¢ Reduced window size from 4K to 1K tokens<br>';
                    html += '‚Ä¢ Massive KV cache memory savings<br>';
                    html += '‚Ä¢ Pre+Post normalization for stability<br>';
                    html += '‚Ä¢ Sweet spot 27B parameter size';
                    html += '</div>';
                    break;
                    
                case 'llama':
                    html += '<div class="example-box">';
                    html += '<strong>Llama 4 Balance (March 2025):</strong><br>';
                    html += '‚Ä¢ Alternating MoE/dense layer strategy<br>';
                    html += '‚Ä¢ Proven GQA over experimental MLA<br>';
                    html += '‚Ä¢ Larger experts (8K) with fewer active (2)<br>';
                    html += '‚Ä¢ 400B total with 17B active parameters<br>';
                    html += '‚Ä¢ Production-ready architecture focus';
                    html += '</div>';
                    break;
                    
                case 'kimi':
                    html += '<div class="example-box">';
                    html += '<strong>Kimi K2 Scale (May 2025):</strong><br>';
                    html += '‚Ä¢ First 1 trillion parameter open-weight model<br>';
                    html += '‚Ä¢ Uses DeepSeek V3 architecture at massive scale<br>';
                    html += '‚Ä¢ Muon optimizer over traditional AdamW<br>';
                    html += '‚Ä¢ Smooth training loss curves<br>';
                    html += '‚Ä¢ Matches proprietary model performance';
                    html += '</div>';
                    break;
            }
            
            html += '</div>';
            document.getElementById('evolutionDetails').innerHTML = html;
        }

        function compareArchitectures() {
            const primary = document.getElementById('primaryModel').value;
            const comparison = document.getElementById('comparisonModel').value;
            const focus = document.getElementById('focusArea').value;
            
            const primarySpec = modelSpecs[primary];
            const comparisonSpec = modelSpecs[comparison];
            
            let html = '<div class="step"><h3>üîç ' + primarySpec.name + ' vs ' + comparisonSpec.name + '</h3>';
            
            // Architecture comparison table
            html += '<div class="comparison-matrix">';
            html += '<table>';
            html += '<tr><th>Aspect</th><th>' + primarySpec.name + '</th><th>' + comparisonSpec.name + '</th><th>Analysis</th></tr>';
            html += '<tr><td><strong>Total Parameters</strong></td><td>' + primarySpec.totalParams + '</td><td>' + comparisonSpec.totalParams + '</td><td>Capacity difference</td></tr>';
            html += '<tr><td><strong>Active Parameters</strong></td><td>' + primarySpec.activeParams + '</td><td>' + comparisonSpec.activeParams + '</td><td>Inference efficiency</td></tr>';
            html += '<tr><td><strong>Attention</strong></td><td>' + primarySpec.attention + '</td><td>' + comparisonSpec.attention + '</td><td>Memory/compute trade-off</td></tr>';
            html += '<tr><td><strong>MoE Strategy</strong></td><td>' + primarySpec.moe + '</td><td>' + comparisonSpec.moe + '</td><td>Scaling approach</td></tr>';
            html += '<tr><td><strong>Key Innovation</strong></td><td>' + primarySpec.keyFeature + '</td><td>' + comparisonSpec.keyFeature + '</td><td>Design philosophy</td></tr>';
            html += '</table>';
            html += '</div>';
            
            if (focus === 'attention') {
                html += '<div class="info">';
                html += '<strong>üéØ Attention Focus:</strong> ' + primarySpec.name + ' uses ' + primarySpec.attention + 
                        ' while ' + comparisonSpec.name + ' uses ' + comparisonSpec.attention + '. ';
                        
                if (primarySpec.attention.includes('MLA')) {
                    html += 'MLA provides superior memory efficiency through KV compression but requires more complex implementation.';
                } else if (primarySpec.attention.includes('Sliding')) {
                    html += 'Sliding window attention reduces memory quadratically while maintaining most performance.';
                } else {
                    html += 'Standard GQA provides proven efficiency with simpler implementation.';
                }
                html += '</div>';
            }
            
            html += '</div>';
            document.getElementById('architectureComparison').innerHTML = html;
        }

        function showDetailedMoEComparison() {
            let html = '<div class="step"><h3>üî¨ MoE Implementation Deep Dive</h3>';
            
            html += '<div class="feature-comparison">';
            html += '<div class="feature-card">';
            html += '<div class="feature-title">üß† DeepSeek V3 MoE Design</div>';
            html += '<div class="math-formula">';
            html += '<strong>Expert Configuration:</strong><br>';
            html += '‚Ä¢ 256 total experts per layer<br>';
            html += '‚Ä¢ 9 active: 8 routed + 1 shared<br>';
            html += '‚Ä¢ Expert size: 2,048 hidden units<br>';
            html += '‚Ä¢ Every layer has MoE (except first 3)<br>';
            html += '‚Ä¢ Shared expert always active<br><br>';
            html += '<strong>Routing Math:</strong><br>';
            html += 'token ‚Üí router ‚Üí top-8 experts + shared<br>';
            html += 'output = Œ£(weight_i √ó expert_i(token)) + shared(token)';
            html += '</div>';
            html += '</div>';
            
            html += '<div class="feature-card">';
            html += '<div class="feature-title">üöÄ Llama 4 MoE Design</div>';
            html += '<div class="math-formula">';
            html += '<strong>Expert Configuration:</strong><br>';
            html += '‚Ä¢ Fewer total experts per layer<br>';
            html += '‚Ä¢ 2 active experts per token<br>';
            html += '‚Ä¢ Expert size: 8,192 hidden units<br>';
            html += '‚Ä¢ Alternates: Layer N=MoE, N+1=Dense<br>';
            html += '‚Ä¢ No shared expert<br><br>';
            html += '<strong>Routing Math:</strong><br>';
            html += 'token ‚Üí router ‚Üí top-2 experts<br>';
            html += 'output = weight_1 √ó expert_1(token) + weight_2 √ó expert_2(token)';
            html += '</div>';
            html += '</div>';
            html += '</div>';
            
            html += '<div class="warning">';
            html += '<strong>üéØ Trade-off Analysis:</strong><br>';
            html += '‚Ä¢ <strong>DeepSeek:</strong> More experts = better specialization, higher routing overhead<br>';
            html += '‚Ä¢ <strong>Llama 4:</strong> Fewer experts = simpler routing, larger expert capacity<br>';
            html += '‚Ä¢ <strong>Shared Expert:</strong> Handles common patterns, reduces expert load imbalance<br>';
            html += '‚Ä¢ <strong>Alternating:</strong> Balances dense computation with sparse scaling';
            html += '</div>';
            
            html += '</div>';
            document.getElementById('moeDetails').innerHTML = html;
        }

        function selectUseCase(useCase) {
            // Remove selection from all cards
            document.querySelectorAll('.arch-card').forEach(card => {
                card.classList.remove('selected');
            });
            
            // Add selection to clicked card
            event.target.classList.add('selected');
            
            let html = '<div class="step"><h3>üéØ ' + useCase.toUpperCase() + ' Use Case Recommendations</h3>';
            
            switch(useCase) {
                case 'research':
                    html += '<div class="info">';
                    html += '<strong>üî¨ Research & Experimentation:</strong><br>';
                    html += '‚Ä¢ <strong>OLMo 2:</strong> Complete transparency, training logs, clean architecture<br>';
                    html += '‚Ä¢ <strong>SmolLM3:</strong> Small scale for quick experiments, NoPE innovation<br>';
                    html += '‚Ä¢ <strong>Benefits:</strong> Reproducible results, educational value, modification-friendly<br>';
                    html += '‚Ä¢ <strong>Trade-offs:</strong> Not state-of-the-art performance, smaller scale';
                    html += '</div>';
                    break;
                    
                case 'production':
                    html += '<div class="success">';
                    html += '<strong>üè≠ Production Deployment:</strong><br>';
                    html += '‚Ä¢ <strong>Llama 4:</strong> Battle-tested, extensive ecosystem, balanced architecture<br>';
                    html += '‚Ä¢ <strong>Gemma 3:</strong> Efficient, well-optimized, good documentation<br>';
                    html += '‚Ä¢ <strong>Benefits:</strong> Proven reliability, optimization support, community resources<br>';
                    html += '‚Ä¢ <strong>Trade-offs:</strong> Less cutting-edge, potentially higher inference costs';
                    html += '</div>';
                    break;
                    
                case 'efficiency':
                    html += '<div class="warning">';
                    html += '<strong>‚ö° Maximum Efficiency:</strong><br>';
                    html += '‚Ä¢ <strong>DeepSeek V3:</strong> MLA compression, optimal MoE design, memory efficient<br>';
                    html += '‚Ä¢ <strong>Qwen3:</strong> Multiple variants, optimized routing, good performance/cost<br>';
                    html += '‚Ä¢ <strong>Benefits:</strong> Lowest inference cost, cutting-edge optimizations<br>';
                    html += '‚Ä¢ <strong>Trade-offs:</strong> Implementation complexity, newer/less tested';
                    html += '</div>';
                    break;
                    
                case 'local':
                    html += '<div class="info">';
                    html += '<strong>üíª Local Deployment:</strong><br>';
                    html += '‚Ä¢ <strong>Gemma 3:</strong> Sliding window reduces memory, multiple sizes<br>';
                    html += '‚Ä¢ <strong>Qwen3 Small:</strong> Excellent small models, efficient architecture<br>';
                    html += '‚Ä¢ <strong>Benefits:</strong> Consumer hardware friendly, privacy control<br>';
                    html += '‚Ä¢ <strong>Trade-offs:</strong> Limited by local compute, smaller model capabilities';
                    html += '</div>';
                    break;
            }
            
            html += '</div>';
            document.getElementById('useCaseDetails').innerHTML = html;
        }

        // Initialize with first comparison
        document.addEventListener('DOMContentLoaded', function() {
            compareArchitectures();
            showEvolution('deepseek');
        });
        // Additional data objects and functions to add to your existing <script> section

// Attention type specifications
const attentionSpecs = {
    'mha': {
        name: 'Multi-Head Attention',
        kvCompression: 1.0,
        complexity: 'O(n¬≤)',
        memory: 'High',
        description: 'Each head has independent K,V matrices'
    },
    'gqa': {
        name: 'Grouped Query Attention',
        kvCompression: 0.25,
        complexity: 'O(n¬≤)',
        memory: 'Medium',
        description: 'Groups share K,V matrices, ~4x memory reduction'
    },
    'mla': {
        name: 'Multi-Head Latent Attention',
        kvCompression: 0.1,
        complexity: 'O(n¬≤)',
        memory: 'Low',
        description: 'Compressed latent space, ~10x memory reduction'
    }
};

// Normalization strategy details
const normStrategies = {
    'pre-norm': {
        name: 'Pre-Normalization',
        stability: 'High',
        performance: 'Good',
        description: 'Normalize before attention/FFN operations',
        gradient: 'Stable gradients, easier training'
    },
    'post-norm': {
        name: 'Post-Normalization',
        stability: 'Medium',
        performance: 'Best',
        description: 'Normalize after residual connections',
        gradient: 'Can have gradient issues but better final performance'
    },
    'qk-norm': {
        name: 'QK-Normalization',
        stability: 'High',
        performance: 'Good',
        description: 'Normalize query and key inside attention',
        gradient: 'Prevents attention collapse'
    },
    'dual-norm': {
        name: 'Pre+Post Normalization',
        stability: 'Highest',
        performance: 'Best',
        description: 'Both pre and post normalization',
        gradient: 'Maximum stability with performance'
    }
};

// Complete model database
const modelDatabase = {
    'olmo-2': {
        name: 'OLMo 2',
        params: '13B',
        attention: 'Multi-Head Attention',
        normalization: 'Post-Norm + QK-Norm',
        position: 'RoPE',
        innovations: ['Training transparency', 'Post-norm return', 'QK normalization'],
        strengths: ['Full training data', 'Educational value', 'Reproducible'],
        weaknesses: ['Smaller scale', 'Research focus'],
        useCase: 'Research and education'
    },
    'gemma-3': {
        name: 'Gemma 3',
        params: '27B',
        attention: 'Sliding Window GQA (5:1 ratio)',
        normalization: 'Pre+Post Normalization',
        position: 'RoPE',
        innovations: ['5:1 sliding window', 'Dual normalization', 'Memory optimization'],
        strengths: ['Memory efficient', 'Local deployment', 'Stable training'],
        weaknesses: ['Limited long context', 'Complex normalization'],
        useCase: 'Production deployment with memory constraints'
    },
    'qwen3': {
        name: 'Qwen3 235B-A22B',
        params: '235B (22B active)',
        attention: 'Grouped Query Attention',
        normalization: 'Pre-Normalization',
        position: 'RoPE',
        innovations: ['Dense+MoE variants', 'Optimized routing', 'Multi-size strategy'],
        strengths: ['Multiple variants', 'Good performance/cost', 'Proven MoE'],
        weaknesses: ['Standard architecture', 'Less innovative'],
        useCase: 'Balanced production deployment'
    },
    'mistral-small': {
        name: 'Mistral Small 3.1',
        params: '22B',
        attention: 'Sliding Window + Flash Attention',
        normalization: 'Pre-Normalization',
        position: 'RoPE',
        innovations: ['Optimized sliding window', 'Flash attention', 'Efficient inference'],
        strengths: ['Fast inference', 'Memory efficient', 'Production ready'],
        weaknesses: ['Smaller scale', 'Limited context'],
        useCase: 'Fast inference applications'
    },
    'smollm3': {
        name: 'SmolLM3',
        params: '8.1B',
        attention: 'Multi-Head Attention',
        normalization: 'Pre-Normalization',
        position: 'NoPE (No Positional Embeddings)',
        innovations: ['No positional embeddings', 'Ultra efficient', 'Causal masking only'],
        strengths: ['Minimal parameters', 'Simple architecture', 'Fast training'],
        weaknesses: ['Limited capability', 'Small scale only'],
        useCase: 'Lightweight applications and research'
    },
    'kimi-k2': {
        name: 'Kimi K2',
        params: '1T (~100B active)',
        attention: 'Multi-Head Latent Attention',
        normalization: 'Pre-Normalization',
        position: 'RoPE',
        innovations: ['Trillion parameters', 'Scaled MLA', 'Muon optimizer'],
        strengths: ['Massive capacity', 'MLA efficiency', 'State-of-art'],
        weaknesses: ['Complex deployment', 'High compute cost'],
        useCase: 'Research and high-end applications'
    }
};

// New Functions for Interactive Features

function calculateAttentionMetrics() {
    const attentionType = document.getElementById('attentionType').value;
    const modelSize = document.getElementById('modelSize').value;
    const seqLength = parseInt(document.getElementById('seqLength').value);
    
    document.getElementById('seqLengthValue').textContent = seqLength;
    
    const spec = attentionSpecs[attentionType];
    const sizeMultiplier = parseInt(modelSize.replace('B', ''));
    
    // Calculate approximate memory usage (simplified)
    const baseMemory = Math.log(sizeMultiplier) * 10; // Base model memory
    const kvCacheBase = (seqLength / 1024) * (sizeMultiplier / 7) * 2; // KV cache base
    const kvCacheActual = kvCacheBase * spec.kvCompression;
    const totalMemory = baseMemory + kvCacheActual;
    
    let html = '<div class="step"><h3>üìä Memory Analysis Results</h3>';
    html += '<div class="comparison-matrix">';
    html += '<table>';
    html += '<tr><th>Metric</th><th>Value</th><th>Analysis</th></tr>';
    html += '<tr><td><strong>Attention Type</strong></td><td>' + spec.name + '</td><td>' + spec.description + '</td></tr>';
    html += '<tr><td><strong>Model Size</strong></td><td>' + modelSize + ' parameters</td><td>Base memory: ~' + baseMemory.toFixed(1) + 'GB</td></tr>';
    html += '<tr><td><strong>Sequence Length</strong></td><td>' + seqLength + ' tokens</td><td>Context window size</td></tr>';
    html += '<tr><td><strong>KV Cache (baseline)</strong></td><td>' + kvCacheBase.toFixed(1) + 'GB</td><td>Standard attention memory</td></tr>';
    html += '<tr><td><strong>KV Cache (optimized)</strong></td><td class="winner">' + kvCacheActual.toFixed(1) + 'GB</td><td>' + ((1-spec.kvCompression)*100).toFixed(0) + '% memory savings</td></tr>';
    html += '<tr><td><strong>Total Memory Est.</strong></td><td>' + totalMemory.toFixed(1) + 'GB</td><td>Inference memory requirement</td></tr>';
    html += '</table>';
    html += '</div>';
    
    // Add efficiency insight
    if (spec.kvCompression < 0.3) {
        html += '<div class="success"><strong>üöÄ Efficiency Leader:</strong> ' + spec.name + ' provides exceptional memory efficiency, making large models practical for deployment.</div>';
    } else if (spec.kvCompression < 0.7) {
        html += '<div class="info"><strong>‚öñÔ∏è Balanced Approach:</strong> ' + spec.name + ' offers good efficiency with proven reliability.</div>';
    } else {
        html += '<div class="warning"><strong>üìä Baseline Approach:</strong> ' + spec.name + ' uses standard memory patterns, prioritizing simplicity.</div>';
    }
    
    html += '</div>';
    document.getElementById('attentionAnalysis').innerHTML = html;
}

function showNormStrategy() {
    const strategy = document.getElementById('normStrategy').value;
    analyzeNormalization();
}

function analyzeNormalization() {
    const strategy = document.getElementById('normStrategy').value;
    const phase = document.getElementById('trainingPhase').value;
    const spec = normStrategies[strategy];
    
    let html = '<div class="step"><h3>üìà Normalization Analysis: ' + spec.name + '</h3>';
    
    html += '<div class="feature-comparison">';
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üî¨ Strategy Details</div>';
    html += '<div class="arch-specs">';
    html += '<strong>Description:</strong> ' + spec.description + '<br>';
    html += '<strong>Training Stability:</strong> ' + spec.stability + '<br>';
    html += '<strong>Final Performance:</strong> ' + spec.performance + '<br>';
    html += '<strong>Gradient Flow:</strong> ' + spec.gradient;
    html += '</div>';
    html += '</div>';
    
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üìä Training Phase Impact</div>';
    
    let phaseDescription = '';
    if (phase === 'early') {
        phaseDescription = strategy === 'pre-norm' ? 
            'Excellent stability, smooth gradient flow' :
            'Potential instability, requires careful learning rates';
    } else if (phase === 'middle') {
        phaseDescription = strategy === 'post-norm' ? 
            'Better performance emergence, stable training' :
            'Continued stability, may plateau earlier';
    } else {
        phaseDescription = strategy === 'post-norm' ? 
            'Achieves best final performance' :
            'Stable but may not reach optimal performance';
    }
    
    html += '<div class="arch-specs">';
    html += '<strong>Phase:</strong> ' + phase.charAt(0).toUpperCase() + phase.slice(1) + ' Training<br>';
    html += '<strong>Impact:</strong> ' + phaseDescription;
    html += '</div>';
    html += '</div>';
    html += '</div>';
    
    html += '</div>';
    document.getElementById('normalizationAnalysis').innerHTML = html;
}

function selectNormType(type) {
    document.getElementById('normStrategy').value = type;
    showNormTypeDetails(type);
}

function showNormTypeDetails(type) {
    const spec = normStrategies[type];
    
    let html = '<div class="step"><h3>üîç ' + spec.name + ' Deep Dive</h3>';
    
    html += '<div class="math-formula">';
    if (type === 'pre-norm') {
        html += '<strong>Pre-Norm Mathematical Flow:</strong><br>';
        html += '1. x‚ÇÅ = x‚ÇÄ + attention(LayerNorm(x‚ÇÄ))<br>';
        html += '2. x‚ÇÇ = x‚ÇÅ + ffn(LayerNorm(x‚ÇÅ))<br>';
        html += '<strong>Benefits:</strong> Gradient flows directly through residual path';
    } else if (type === 'post-norm') {
        html += '<strong>Post-Norm Mathematical Flow:</strong><br>';
        html += '1. x‚ÇÅ = LayerNorm(x‚ÇÄ + attention(x‚ÇÄ))<br>';
        html += '2. x‚ÇÇ = LayerNorm(x‚ÇÅ + ffn(x‚ÇÅ))<br>';
        html += '<strong>Benefits:</strong> Stronger normalization, better final performance';
    } else if (type === 'qk-norm') {
        html += '<strong>QK-Norm Mathematical Flow:</strong><br>';
        html += '1. Q = LayerNorm_Q(query_projection(x))<br>';
        html += '2. K = LayerNorm_K(key_projection(x))<br>';
        html += '3. attention(Q, K, V) ‚Üí normalized attention<br>';
        html += '<strong>Benefits:</strong> Prevents attention collapse, stable training';
    } else {
        html += '<strong>Dual-Norm Mathematical Flow:</strong><br>';
        html += '1. x‚ÇÅ = LayerNorm_post(x‚ÇÄ + attention(LayerNorm_pre(x‚ÇÄ)))<br>';
        html += '2. x‚ÇÇ = LayerNorm_post(x‚ÇÅ + ffn(LayerNorm_pre(x‚ÇÅ)))<br>';
        html += '<strong>Benefits:</strong> Maximum stability with optimal performance';
    }
    html += '</div>';
    
    html += '</div>';
    document.getElementById('normTypeDetails').innerHTML = html;
}

function showModelDetails() {
    const modelKey = document.getElementById('modelFocus').value;
    const model = modelDatabase[modelKey];
    
    let html = '<div class="step"><h3>üîç ' + model.name + ' Architecture Deep Dive</h3>';
    
    html += '<div class="feature-comparison">';
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üèóÔ∏è Architecture Specifications</div>';
    html += '<div class="arch-specs">';
    html += '<strong>Parameters:</strong> ' + model.params + '<br>';
    html += '<strong>Attention:</strong> ' + model.attention + '<br>';
    html += '<strong>Normalization:</strong> ' + model.normalization + '<br>';
    html += '<strong>Position Encoding:</strong> ' + model.position + '<br>';
    html += '<strong>Primary Use Case:</strong> ' + model.useCase;
    html += '</div>';
    html += '</div>';
    
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üí° Key Innovations</div>';
    html += '<div class="arch-specs">';
    model.innovations.forEach(innovation => {
        html += '‚Ä¢ ' + innovation + '<br>';
    });
    html += '</div>';
    html += '</div>';
    html += '</div>';
    
    html += '<div class="feature-comparison">';
    html += '<div class="feature-card">';
    html += '<div class="feature-title">‚úÖ Strengths</div>';
    html += '<div class="arch-specs">';
    model.strengths.forEach(strength => {
        html += '‚Ä¢ ' + strength + '<br>';
    });
    html += '</div>';
    html += '</div>';
    
    html += '<div class="feature-card">';
    html += '<div class="feature-title">‚ö†Ô∏è Considerations</div>';
    html += '<div class="arch-specs">';
    model.weaknesses.forEach(weakness => {
        html += '‚Ä¢ ' + weakness + '<br>';
    });
    html += '</div>';
    html += '</div>';
    html += '</div>';
    
    html += '</div>';
    document.getElementById('modelDetailsContainer').innerHTML = html;
}

function showEfficiencyDetails() {
    const tech = document.getElementById('efficiencyTech').value;
    
    document.getElementById('efficiencySizeValue').textContent = document.getElementById('efficiencySize').value;
    document.getElementById('efficiencySeqValue').textContent = document.getElementById('efficiencySeq').value;
}

function calculateEfficiency() {
    const tech = document.getElementById('efficiencyTech').value;
    const size = parseInt(document.getElementById('efficiencySize').value);
    const seqLen = parseInt(document.getElementById('efficiencySeq').value);
    
    let html = '<div class="step"><h3>‚ö° Efficiency Analysis Results</h3>';
    
    if (tech === 'sliding-window') {
        const standardMemory = Math.pow(seqLen / 1024, 2) * size / 10;
        const slidingMemory = 1 * size / 10; // Constant for sliding window
        const savings = ((standardMemory - slidingMemory) / standardMemory * 100);
        
        html += '<div class="comparison-matrix">';
        html += '<table>';
        html += '<tr><th>Metric</th><th>Standard Attention</th><th>Sliding Window</th><th>Improvement</th></tr>';
        html += '<tr><td><strong>Memory Usage</strong></td><td>' + standardMemory.toFixed(1) + 'GB</td><td class="winner">' + slidingMemory.toFixed(1) + 'GB</td><td class="winner">' + savings.toFixed(0) + '% less</td></tr>';
        html += '<tr><td><strong>Attention Ops</strong></td><td>O(n¬≤)</td><td class="winner">O(window)</td><td class="winner">Linear scaling</td></tr>';
        html += '<tr><td><strong>Context Length</strong></td><td>Full sequence</td><td class="moderate">Local window</td><td class="moderate">Trade-off</td></tr>';
        html += '</table>';
        html += '</div>';
        
    } else if (tech === 'mla-compression') {
        const standardKV = seqLen * size / 100;
        const compressedKV = standardKV * 0.1;
        const savings = ((standardKV - compressedKV) / standardKV * 100);
        
        html += '<div class="comparison-matrix">';
        html += '<table>';
        html += '<tr><th>Metric</th><th>Standard KV Cache</th><th>MLA Compressed</th><th>Improvement</th></tr>';
        html += '<tr><td><strong>KV Cache Size</strong></td><td>' + standardKV.toFixed(1) + 'GB</td><td class="winner">' + compressedKV.toFixed(1) + 'GB</td><td class="winner">' + savings.toFixed(0) + '% less</td></tr>';
        html += '<tr><td><strong>Compression Ratio</strong></td><td>1:1</td><td class="winner">10:1</td><td class="winner">90% reduction</td></tr>';
        html += '<tr><td><strong>Performance</strong></td><td>Baseline</td><td class="winner">Equal/Better</td><td class="winner">No degradation</td></tr>';
        html += '</table>';
        html += '</div>';
    }
    
    html += '</div>';
    document.getElementById('efficiencyCalculator').innerHTML = html;
}

// Intelligent Architecture Builder - Replace the existing buildArchitecture() and analyzeTradeoffs() functions

// Architecture component database with real specifications
const architectureComponents = {
    attention: {
        'mha': {
            name: 'Multi-Head Attention',
            memoryMultiplier: 1.0,
            computeComplexity: 'O(n¬≤d)',
            implementationDifficulty: 1,
            qualityScore: 8,
            bestFor: ['research', 'transparency'],
            realModels: ['GPT-1', 'GPT-2', 'BERT'],
            pros: ['Simple implementation', 'Well understood', 'Debuggable'],
            cons: ['High memory usage', 'Inefficient for long sequences', 'No sharing']
        },
        'gqa': {
            name: 'Grouped Query Attention',
            memoryMultiplier: 0.25,
            computeComplexity: 'O(n¬≤d/g)',
            implementationDifficulty: 3,
            qualityScore: 9,
            bestFor: ['production', 'balanced'],
            realModels: ['Llama 2/3/4', 'GPT-4', 'Gemma'],
            pros: ['4x memory reduction', 'Proven in production', 'Good quality retention'],
            cons: ['Slightly more complex', 'Group size tuning needed']
        },
        'mla': {
            name: 'Multi-Head Latent Attention',
            memoryMultiplier: 0.1,
            computeComplexity: 'O(n¬≤c + nd)',
            implementationDifficulty: 8,
            qualityScore: 9.5,
            bestFor: ['efficiency', 'large-scale'],
            realModels: ['DeepSeek V3', 'Kimi K2'],
            pros: ['90% memory reduction', 'Superior scaling', 'Maintains quality'],
            cons: ['Complex implementation', 'New/unproven', 'Training complexity']
        },
        'sliding': {
            name: 'Sliding Window Attention',
            memoryMultiplier: 0.1,
            computeComplexity: 'O(nwd)',
            implementationDifficulty: 4,
            qualityScore: 8.5,
            bestFor: ['local', 'consumer'],
            realModels: ['Gemma 3', 'Mistral', 'Longformer'],
            pros: ['Constant memory', 'Linear scaling', 'Local efficiency'],
            cons: ['Limited long context', 'Pattern limitations', 'Window tuning']
        }
    },
    normalization: {
        'pre-norm': {
            name: 'Pre-Normalization',
            trainingStability: 9,
            finalPerformance: 7,
            implementationDifficulty: 1,
            bestFor: ['training', 'stability'],
            realModels: ['Llama', 'GPT-3+', 'Most modern'],
            pros: ['Excellent stability', 'Easy training', 'Proven approach'],
            cons: ['Slightly lower performance', 'Less expressive']
        },
        'post-norm': {
            name: 'Post-Normalization',
            trainingStability: 6,
            finalPerformance: 9,
            implementationDifficulty: 2,
            bestFor: ['performance', 'research'],
            realModels: ['Original Transformer', 'OLMo 2'],
            pros: ['Best final performance', 'More expressive', 'Better gradients'],
            cons: ['Training instability', 'Requires expertise', 'Careful tuning']
        },
        'qk-norm': {
            name: 'QK-Normalization',
            trainingStability: 8,
            finalPerformance: 8,
            implementationDifficulty: 3,
            bestFor: ['attention-stability', 'research'],
            realModels: ['OLMo 2'],
            pros: ['Prevents collapse', 'Stable attention', 'Good performance'],
            cons: ['Extra computation', 'Limited adoption', 'Research stage']
        },
        'dual-norm': {
            name: 'Pre+Post Normalization',
            trainingStability: 9,
            finalPerformance: 9,
            implementationDifficulty: 4,
            bestFor: ['maximum-quality', 'resources-available'],
            realModels: ['Gemma 3'],
            pros: ['Best of both worlds', 'Maximum stability', 'Top performance'],
            cons: ['2x normalization cost', 'Complex implementation', 'Memory overhead']
        }
    },
    ffn: {
        'dense': {
            name: 'Dense Feed-Forward',
            parameterEfficiency: 1.0,
            implementationDifficulty: 1,
            scalingPotential: 5,
            bestFor: ['simplicity', 'small-models'],
            realModels: ['Most models <30B'],
            pros: ['Simple and reliable', 'Predictable behavior', 'Easy debugging'],
            cons: ['Poor parameter efficiency', 'Limited scaling', 'Monolithic']
        },
        'moe': {
            name: 'Mixture of Experts',
            parameterEfficiency: 8.0,
            implementationDifficulty: 7,
            scalingPotential: 10,
            bestFor: ['large-scale', 'efficiency'],
            realModels: ['Switch-T', 'PaLM-2', 'DeepSeek V3'],
            pros: ['Massive parameter scaling', 'Specialized experts', 'Conditional compute'],
            cons: ['Complex routing', 'Load balancing', 'Training challenges']
        },
        'alternating': {
            name: 'Alternating Dense/MoE',
            parameterEfficiency: 6.0,
            implementationDifficulty: 5,
            scalingPotential: 8,
            bestFor: ['balanced-scaling', 'production'],
            realModels: ['Llama 4'],
            pros: ['Balanced approach', 'Easier than full MoE', 'Good scaling'],
            cons: ['Still complex', 'Suboptimal efficiency', 'Mixed benefits']
        }
    }
};

// Use case requirements
const useCaseRequirements = {
    'general': {
        name: 'General Purpose',
        memoryConstraint: 'medium',
        performanceRequirement: 'high',
        complexityTolerance: 'medium',
        priorityOrder: ['quality', 'reliability', 'efficiency']
    },
    'code': {
        name: 'Code Generation',
        memoryConstraint: 'medium',
        performanceRequirement: 'very-high',
        complexityTolerance: 'high',
        priorityOrder: ['quality', 'precision', 'context']
    },
    'research': {
        name: 'Research/Science',
        memoryConstraint: 'low',
        performanceRequirement: 'medium',
        complexityTolerance: 'very-high',
        priorityOrder: ['transparency', 'reproducibility', 'innovation']
    },
    'chat': {
        name: 'Chat/Assistant',
        memoryConstraint: 'high',
        performanceRequirement: 'high',
        complexityTolerance: 'low',
        priorityOrder: ['reliability', 'speed', 'efficiency']
    },
    'local': {
        name: 'Local Deployment',
        memoryConstraint: 'very-high',
        performanceRequirement: 'medium',
        complexityTolerance: 'low',
        priorityOrder: ['efficiency', 'simplicity', 'memory']
    }
};

function buildArchitecture() {
    const baseArch = document.getElementById('baseArch').value;
    const attention = document.getElementById('builderAttention').value;
    const norm = document.getElementById('builderNorm').value;
    const ffn = document.getElementById('builderFFN').value;
    const position = document.getElementById('builderPosition').value;
    const size = parseInt(document.getElementById('builderSize').value);
    const useCase = document.getElementById('builderUseCase').value;
    
    document.getElementById('builderSizeValue').textContent = size;
    
    // Get component specs
    const attentionSpec = architectureComponents.attention[attention];
    const normSpec = architectureComponents.normalization[norm];
    const ffnSpec = architectureComponents.ffn[ffn];
    const useCaseSpec = useCaseRequirements[useCase];
    
    // Calculate real metrics
    const metrics = calculateArchitectureMetrics(size, attentionSpec, normSpec, ffnSpec);
    const compatibility = analyzeUseCaseCompatibility(useCaseSpec, attentionSpec, normSpec, ffnSpec);
    const improvements = suggestImprovements(useCase, attention, norm, ffn, size);
    
    let html = '<div class="step"><h3>üèóÔ∏è Your Custom Architecture Analysis</h3>';
    
    // Architecture Overview
    html += '<div class="feature-comparison">';
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üìã Architecture Specification</div>';
    html += '<div class="arch-specs">';
    html += '<strong>Base:</strong> ' + baseArch.charAt(0).toUpperCase() + baseArch.slice(1) + '<br>';
    html += '<strong>Size:</strong> ' + size + 'B parameters<br>';
    html += '<strong>Attention:</strong> ' + attentionSpec.name + '<br>';
    html += '<strong>Normalization:</strong> ' + normSpec.name + '<br>';
    html += '<strong>FFN Strategy:</strong> ' + ffnSpec.name + '<br>';
    html += '<strong>Position Encoding:</strong> ' + position.toUpperCase() + '<br>';
    html += '<strong>Target Use Case:</strong> ' + useCaseSpec.name;
    html += '</div>';
    html += '</div>';
    
    // Real Performance Metrics
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üìä Performance Metrics</div>';
    html += '<div class="arch-specs">';
    html += '<strong>Memory Usage:</strong> ~' + metrics.memoryGB.toFixed(1) + 'GB<br>';
    html += '<strong>Training Stability:</strong> ' + getScoreText(metrics.trainingStability) + '<br>';
    html += '<strong>Final Quality:</strong> ' + getScoreText(metrics.finalQuality) + '<br>';
    html += '<strong>Implementation:</strong> ' + getDifficultyText(metrics.implementationDifficulty) + '<br>';
    html += '<strong>Inference Speed:</strong> ' + getSpeedText(metrics.inferenceSpeed) + '<br>';
    html += '<strong>Active Parameters:</strong> ~' + metrics.activeParams.toFixed(1) + 'B';
    html += '</div>';
    html += '</div>';
    html += '</div>';
    
    // Use Case Compatibility Analysis
    html += '<div class="comparison-matrix">';
    html += '<table>';
    html += '<tr><th>Compatibility Aspect</th><th>Score</th><th>Analysis</th></tr>';
    html += '<tr><td><strong>Memory Constraint</strong></td><td class="' + getScoreClass(compatibility.memoryScore) + '">' + compatibility.memoryScore + '/10</td><td>' + compatibility.memoryAnalysis + '</td></tr>';
    html += '<tr><td><strong>Performance Requirement</strong></td><td class="' + getScoreClass(compatibility.performanceScore) + '">' + compatibility.performanceScore + '/10</td><td>' + compatibility.performanceAnalysis + '</td></tr>';
    html += '<tr><td><strong>Implementation Complexity</strong></td><td class="' + getScoreClass(compatibility.complexityScore) + '">' + compatibility.complexityScore + '/10</td><td>' + compatibility.complexityAnalysis + '</td></tr>';
    html += '<tr><td><strong>Overall Fit</strong></td><td class="' + getScoreClass(compatibility.overallScore) + '"><strong>' + compatibility.overallScore + '/10</strong></td><td><strong>' + compatibility.overallAnalysis + '</strong></td></tr>';
    html += '</table>';
    html += '</div>';
    
    // Intelligent Recommendations
    if (improvements.length > 0) {
        html += '<div class="warning">';
        html += '<strong>üîß Recommended Improvements:</strong><br>';
        improvements.forEach(improvement => {
            html += '‚Ä¢ ' + improvement + '<br>';
        });
        html += '</div>';
    }
    
    // Similar Real-World Architectures
    const similarModels = findSimilarArchitectures(attention, norm, ffn);
    if (similarModels.length > 0) {
        html += '<div class="info">';
        html += '<strong>üéØ Similar Real Architectures:</strong><br>';
        html += 'Your design is similar to: ' + similarModels.join(', ') + '<br>';
        html += 'This suggests your choices align with proven production architectures.';
        html += '</div>';
    }
    
    html += '</div>';
    document.getElementById('architectureBuilder').innerHTML = html;
}

function calculateArchitectureMetrics(size, attentionSpec, normSpec, ffnSpec) {
    // Base memory calculation (more realistic)
    const baseMemory = size * 2; // 2GB per billion parameters (FP16)
    const kvCacheMemory = (size / 10) * attentionSpec.memoryMultiplier * 8; // 8K context assumption
    const totalMemory = baseMemory + kvCacheMemory;
    
    // Training stability (weighted average)
    const trainingStability = (normSpec.trainingStability * 0.6 + attentionSpec.qualityScore * 0.4);
    
    // Final quality (weighted by components)
    const finalQuality = (
        attentionSpec.qualityScore * 0.4 + 
        normSpec.finalPerformance * 0.3 + 
        Math.min(size / 10, 10) * 0.3  // Size factor (up to 100B)
    );
    
    // Implementation difficulty (max of components)
    const implementationDifficulty = Math.max(
        attentionSpec.implementationDifficulty,
        normSpec.implementationDifficulty,
        ffnSpec.implementationDifficulty
    );
    
    // Inference speed (inverse of memory and complexity)
    const inferenceSpeed = 10 - (attentionSpec.memoryMultiplier * 5 + implementationDifficulty * 0.5);
    
    // Active parameters (for MoE)
    const activeParams = ffn === 'moe' ? size * 0.125 : ffn === 'alternating' ? size * 0.6 : size;
    
    return {
        memoryGB: totalMemory,
        trainingStability: trainingStability,
        finalQuality: finalQuality,
        implementationDifficulty: implementationDifficulty,
        inferenceSpeed: Math.max(1, inferenceSpeed),
        activeParams: activeParams
    };
}

function analyzeUseCaseCompatibility(useCaseSpec, attentionSpec, normSpec, ffnSpec) {
    let memoryScore = 10;
    let memoryAnalysis = '';
    
    // Memory constraint analysis
    if (useCaseSpec.memoryConstraint === 'very-high') {
        memoryScore = attentionSpec.memoryMultiplier < 0.3 ? 9 : attentionSpec.memoryMultiplier < 0.5 ? 6 : 3;
        memoryAnalysis = attentionSpec.memoryMultiplier < 0.3 ? 'Excellent for memory-constrained deployment' : 
                        attentionSpec.memoryMultiplier < 0.5 ? 'Moderate memory usage, may need optimization' :
                        'High memory usage, challenging for local deployment';
    } else if (useCaseSpec.memoryConstraint === 'high') {
        memoryScore = attentionSpec.memoryMultiplier < 0.5 ? 8 : attentionSpec.memoryMultiplier < 0.8 ? 6 : 4;
        memoryAnalysis = 'Memory usage ' + (memoryScore > 7 ? 'acceptable' : memoryScore > 5 ? 'moderate' : 'concerning') + ' for this use case';
    } else {
        memoryScore = 8; // Less critical for cloud deployment
        memoryAnalysis = 'Memory usage not a primary constraint for this use case';
    }
    
    // Performance requirement analysis
    let performanceScore = Math.round((attentionSpec.qualityScore + normSpec.finalPerformance) / 2);
    let performanceAnalysis = performanceScore > 8 ? 'Excellent performance expected' :
                             performanceScore > 6 ? 'Good performance expected' :
                             'Performance may be limiting factor';
    
    // Complexity analysis
    let complexityScore = 10;
    const totalComplexity = attentionSpec.implementationDifficulty + normSpec.implementationDifficulty + ffnSpec.implementationDifficulty;
    
    if (useCaseSpec.complexityTolerance === 'low') {
        complexityScore = totalComplexity < 6 ? 9 : totalComplexity < 10 ? 6 : 3;
    } else if (useCaseSpec.complexityTolerance === 'medium') {
        complexityScore = totalComplexity < 10 ? 8 : totalComplexity < 15 ? 6 : 4;
    } else {
        complexityScore = 8; // High tolerance
    }
    
    let complexityAnalysis = complexityScore > 7 ? 'Implementation complexity manageable' :
                            complexityScore > 5 ? 'Moderate implementation challenges' :
                            'High implementation complexity, consider simpler alternatives';
    
    // Overall score and analysis
    const overallScore = Math.round((memoryScore + performanceScore + complexityScore) / 3);
    let overallAnalysis = '';
    
    if (overallScore >= 8) {
        overallAnalysis = 'Excellent fit for your use case';
    } else if (overallScore >= 6) {
        overallAnalysis = 'Good fit with some trade-offs';
    } else if (overallScore >= 4) {
        overallAnalysis = 'Workable but significant compromises needed';
    } else {
        overallAnalysis = 'Poor fit, consider major changes';
    }
    
    return {
        memoryScore, memoryAnalysis,
        performanceScore, performanceAnalysis,
        complexityScore, complexityAnalysis,
        overallScore, overallAnalysis
    };
}

function suggestImprovements(useCase, attention, norm, ffn, size) {
    const improvements = [];
    const useCaseSpec = useCaseRequirements[useCase];
    
    // Memory-specific improvements
    if (useCaseSpec.memoryConstraint === 'very-high' || useCaseSpec.memoryConstraint === 'high') {
        if (attention === 'mha') {
            improvements.push('Switch to GQA or MLA for 4-10x memory reduction');
        }
        if (attention === 'gqa' && size > 70) {
            improvements.push('Consider MLA for large models to reduce KV cache memory');
        }
        if (ffn === 'dense' && size > 30) {
            improvements.push('Use MoE to reduce active parameters while maintaining capacity');
        }
    }
    
    // Performance-specific improvements
    if (useCaseSpec.performanceRequirement === 'very-high') {
        if (norm === 'pre-norm') {
            improvements.push('Consider Post-Norm or Dual-Norm for maximum performance');
        }
        if (attention === 'sliding' && useCase === 'code') {
            improvements.push('Use full attention for code generation - long context is critical');
        }
    }
    
    // Complexity-specific improvements
    if (useCaseSpec.complexityTolerance === 'low') {
        if (attention === 'mla') {
            improvements.push('MLA is very complex - consider proven GQA for production');
        }
        if (ffn === 'moe') {
            improvements.push('MoE adds significant complexity - consider dense FFN for simplicity');
        }
        if (norm === 'dual-norm') {
            improvements.push('Dual normalization adds complexity - Pre-Norm is simpler and reliable');
        }
    }
    
    // Size-specific improvements
    if (size < 7) {
        improvements.push('Small models benefit from simpler architectures - consider standard attention and dense FFN');
    }
    if (size > 100 && ffn === 'dense') {
        improvements.push('Large models should use MoE for parameter efficiency');
    }
    
    // Use case specific
    if (useCase === 'research' && attention !== 'mha') {
        improvements.push('Research benefits from MHA transparency - complex attention may hinder analysis');
    }
    if (useCase === 'local' && size > 30) {
        improvements.push('Local deployment works better with smaller models (7-27B range)');
    }
    
    return improvements;
}

function findSimilarArchitectures(attention, norm, ffn) {
    const similar = [];
    
    // Match real architectures
    if (attention === 'gqa' && norm === 'pre-norm' && (ffn === 'dense' || ffn === 'alternating')) {
        similar.push('Llama 2/3/4 family');
    }
    if (attention === 'mla' && ffn === 'moe') {
        similar.push('DeepSeek V3', 'Kimi K2');
    }
    if (attention === 'sliding' && norm === 'dual-norm') {
        similar.push('Gemma 3');
    }
    if (attention === 'mha' && norm === 'post-norm') {
        similar.push('Original Transformer', 'OLMo 2');
    }
    if (attention === 'gqa' && norm === 'pre-norm' && ffn === 'dense') {
        similar.push('Gemma 2', 'Qwen series');
    }
    
    return similar;
}

// Helper functions for display
function getScoreText(score) {
    if (score >= 8.5) return 'Excellent';
    if (score >= 7) return 'Good';
    if (score >= 5.5) return 'Moderate';
    if (score >= 4) return 'Poor';
    return 'Very Poor';
}

function getScoreClass(score) {
    if (score >= 8) return 'winner';
    if (score >= 6) return 'moderate';
    return 'poor';
}

function getDifficultyText(difficulty) {
    if (difficulty <= 2) return 'Simple';
    if (difficulty <= 4) return 'Moderate';
    if (difficulty <= 6) return 'Complex';
    return 'Very Complex';
}

function getSpeedText(speed) {
    if (speed >= 8) return 'Very Fast';
    if (speed >= 6) return 'Fast';
    if (speed >= 4) return 'Moderate';
    return 'Slow';
}

// Enhanced trade-off analysis
function analyzeTradeoffs() {
    const attention = document.getElementById('builderAttention').value;
    const norm = document.getElementById('builderNorm').value;
    const ffn = document.getElementById('builderFFN').value;
    const size = parseInt(document.getElementById('builderSize').value);
    const useCase = document.getElementById('builderUseCase').value;
    
    const attentionSpec = architectureComponents.attention[attention];
    const normSpec = architectureComponents.normalization[norm];
    const ffnSpec = architectureComponents.ffn[ffn];
    
    let html = '<div class="step"><h3>‚öñÔ∏è Intelligent Trade-off Analysis</h3>';
    
    // Component-by-component analysis
    html += '<div class="comparison-matrix">';
    html += '<table>';
    html += '<tr><th>Component</th><th>Choice</th><th>Key Benefits</th><th>Major Trade-offs</th><th>Real Examples</th></tr>';
    
    html += '<tr><td><strong>Attention</strong></td><td>' + attentionSpec.name + '</td>';
    html += '<td class="winner">' + attentionSpec.pros.slice(0,2).join(', ') + '</td>';
    html += '<td class="moderate">' + attentionSpec.cons.slice(0,2).join(', ') + '</td>';
    html += '<td>' + attentionSpec.realModels.slice(0,2).join(', ') + '</td></tr>';
    
    html += '<tr><td><strong>Normalization</strong></td><td>' + normSpec.name + '</td>';
    html += '<td class="winner">' + normSpec.pros.slice(0,2).join(', ') + '</td>';
    html += '<td class="moderate">' + normSpec.cons.slice(0,2).join(', ') + '</td>';
    html += '<td>' + normSpec.realModels.slice(0,2).join(', ') + '</td></tr>';
    
    html += '<tr><td><strong>FFN Strategy</strong></td><td>' + ffnSpec.name + '</td>';
    html += '<td class="winner">' + ffnSpec.pros.slice(0,2).join(', ') + '</td>';
    html += '<td class="moderate">' + ffnSpec.cons.slice(0,2).join(', ') + '</td>';
    html += '<td>' + ffnSpec.realModels.slice(0,2).join(', ') + '</td></tr>';
    
    html += '</table>';
    html += '</div>';
    
    // Strategic analysis
    const totalComplexity = attentionSpec.implementationDifficulty + normSpec.implementationDifficulty + ffnSpec.implementationDifficulty;
    const memoryEfficiency = attentionSpec.memoryMultiplier * (ffn === 'moe' ? 0.125 : 1);
    const expectedQuality = (attentionSpec.qualityScore + normSpec.finalPerformance) / 2;
    
    html += '<div class="feature-comparison">';
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üìä Strategic Analysis</div>';
    html += '<div class="arch-specs">';
    html += '<strong>Implementation Risk:</strong> ' + (totalComplexity > 12 ? 'High - requires expert team' : totalComplexity > 8 ? 'Medium - manageable with planning' : 'Low - straightforward implementation') + '<br>';
    html += '<strong>Memory Efficiency:</strong> ' + (memoryEfficiency < 0.2 ? 'Excellent - cutting edge efficiency' : memoryEfficiency < 0.5 ? 'Good - reasonable memory usage' : 'Standard - may need optimization') + '<br>';
    html += '<strong>Performance Potential:</strong> ' + (expectedQuality > 8.5 ? 'Excellent - top-tier performance' : expectedQuality > 7 ? 'Good - solid performance' : 'Moderate - may limit capabilities') + '<br>';
    html += '<strong>Production Readiness:</strong> ' + (totalComplexity < 8 && attentionSpec.realModels.length > 1 ? 'High - proven in production' : 'Medium to Low - needs validation');
    html += '</div>';
    html += '</div>';
    
    html += '<div class="feature-card">';
    html += '<div class="feature-title">üéØ Recommendation</div>';
    
    let recommendation = '';
    if (totalComplexity > 15) {
        recommendation = 'üö® Very high complexity - consider simplifying for production use';
    } else if (memoryEfficiency < 0.15 && expectedQuality > 8) {
        recommendation = 'üöÄ Cutting-edge efficiency with excellent quality - suitable for research/advanced production';
    } else if (totalComplexity < 8 && expectedQuality > 7.5) {
        recommendation = '‚úÖ Well-balanced architecture - excellent for production deployment';
    } else if (useCase === 'local' && memoryEfficiency > 0.5) {
        recommendation = '‚ö†Ô∏è May be too memory-intensive for local deployment - consider optimizations';
    } else {
        recommendation = '‚öñÔ∏è Reasonable trade-offs - validate performance against requirements';
    }
    
    html += '<div class="arch-specs">' + recommendation + '</div>';
    html += '</div>';
    html += '</div>';
    
    html += '</div>';
    document.getElementById('recommendationEngine').innerHTML = html;
}

// Update range sliders and initialize new functions
document.addEventListener('DOMContentLoaded', function() {
    // Existing initialization
    compareArchitectures();
    showEvolution('deepseek');
    
    // New initializations
    calculateAttentionMetrics();
    showModelDetails();
    showEfficiencyDetails();
    analyzeNormalization();
    
    // Add event listeners for range sliders
    document.getElementById('seqLength').addEventListener('input', function() {
        document.getElementById('seqLengthValue').textContent = this.value;
    });
    
    document.getElementById('efficiencySize').addEventListener('input', function() {
        document.getElementById('efficiencySizeValue').textContent = this.value;
    });
    
    document.getElementById('efficiencySeq').addEventListener('input', function() {
        document.getElementById('efficiencySeqValue').textContent = this.value;
    });
    
    document.getElementById('builderSize').addEventListener('input', function() {
        document.getElementById('builderSizeValue').textContent = this.value;
    });
});
    </script>
</body>
</html>
