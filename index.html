<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Transformer Architecture Tutorials</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);
            color: #e0e0e0;
            line-height: 1.6;
            min-height: 100vh;
        }
        
        .container {
            background: #ffffff;
            color: #2d2d2d;
            border-radius: 20px;
            padding: 40px;
            margin: 20px 0;
            border: 1px solid #e0e0e0;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            background: linear-gradient(135deg, #2d2d2d, #4a4a4a);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .header p {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 0;
        }
        
        .tutorial-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }
        
        .tutorial-card {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 15px;
            padding: 25px;
            transition: all 0.3s ease;
            text-decoration: none;
            color: inherit;
            display: block;
        }
        
        .tutorial-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
            border-color: #2d2d2d;
        }
        
        .tutorial-icon {
            font-size: 2.5em;
            margin-bottom: 15px;
            display: block;
        }
        
        .tutorial-title {
            font-size: 1.3em;
            font-weight: bold;
            margin-bottom: 10px;
            color: #2d2d2d;
        }
        
        .tutorial-description {
            color: #666;
            margin-bottom: 15px;
            line-height: 1.5;
        }
        
        .tutorial-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }
        
        .tag {
            background: #2d2d2d;
            color: white;
            padding: 4px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: 500;
        }
        
        .coming-soon {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none !important;
        }
        
        .coming-soon:hover {
            transform: none !important;
            box-shadow: none !important;
        }
        
        .coming-soon-badge {
            background: #ffc107;
            color: #2d2d2d;
            padding: 4px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: bold;
            margin-left: 10px;
        }
        
        .stats {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin: 30px 0;
            text-align: center;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 20px;
        }
        
        .stat-item {
            text-align: center;
        }
        
        .stat-number {
            font-size: 2em;
            font-weight: bold;
            color: #2d2d2d;
        }
        
        .stat-label {
            color: #666;
            font-size: 0.9em;
        }
        
        .footer {
            text-align: center;
            padding: 20px 0;
            border-top: 1px solid #e9ecef;
            margin-top: 40px;
            color: #666;
        }
        
        .github-link {
            display: inline-block;
            background: #2d2d2d;
            color: white;
            padding: 10px 20px;
            border-radius: 8px;
            text-decoration: none;
            margin-top: 15px;
            transition: background 0.3s ease;
        }
        
        .github-link:hover {
            background: #1a1a1a;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß† Interactive Transformer Tutorials</h1>
            <p>Learn transformer architecture concepts through hands-on visualizations</p>
        </div>
        
        <div class="stats">
            <div class="stats-grid">
                <div class="stat-item">
                    <div class="stat-number">3</div>
                    <div class="stat-label">Interactive Tutorials</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">6+</div>
                    <div class="stat-label">Major Models Covered</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">1M+</div>
                    <div class="stat-label">Token Context Explained</div>
                </div>
            </div>
        </div>
        
        <div class="tutorial-grid">
            <!-- Available Tutorials -->
            <a href="rope-tutorial.html" class="tutorial-card">
                <div class="tutorial-icon">üåÄ</div>
                <div class="tutorial-title">RoPE: Rotary Position Embedding</div>
                <div class="tutorial-description">
                    Understand how transformers encode position information through rotation. Learn why context extension works and how the same model behaves with different sequence lengths.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Position Encoding</span>
                    <span class="tag">Context Extension</span>
                    <span class="tag">Interactive</span>
                </div>
            </a>
            
            <a href="qkv-matrices.html" class="tutorial-card">
                <div class="tutorial-icon">üéØ</div>
                <div class="tutorial-title">Q, K, V Matrix Dimensions</div>
                <div class="tutorial-description">
                    Explore how model dimension (d) and sequence position (m) affect matrix sizes. Compare architectures from GPT-4 to Claude Sonnet 4 with real-world examples.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Attention Mechanism</span>
                    <span class="tag">Matrix Operations</span>
                    <span class="tag">Model Comparison</span>
                </div>
            </a>
            
            <a href="context-length-impact-tutorial.html" class="tutorial-card">
                <div class="tutorial-icon">üìä</div>
                <div class="tutorial-title">Context Length Impact: Training vs Inference</div>
                <div class="tutorial-description">
                    Discover why models trained on long contexts excel at shorter sequences. Step-by-step mathematical analysis with concrete performance metrics and RoPE frequency explanations.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Context Extension</span>
                    <span class="tag">Performance Analysis</span>
                    <span class="tag">Mathematical Proof</span>
                </div>
            </a>
            
            <!-- Coming Soon Tutorials -->
            <div class="tutorial-card coming-soon">
                <div class="tutorial-icon">‚ö°</div>
                <div class="tutorial-title">
                    Attention Optimization Techniques
                    <span class="coming-soon-badge">Coming Soon</span>
                </div>
                <div class="tutorial-description">
                    Flash Attention, sparse attention, and other methods to make attention computation efficient. Interactive demonstrations of memory and speed optimizations.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Flash Attention</span>
                    <span class="tag">Optimization</span>
                    <span class="tag">Performance</span>
                </div>
            </div>
            
            <div class="tutorial-card coming-soon">
                <div class="tutorial-icon">üèóÔ∏è</div>
                <div class="tutorial-title">
                    Transformer Architecture Deep Dive
                    <span class="coming-soon-badge">Coming Soon</span>
                </div>
                <div class="tutorial-description">
                    Complete walkthrough of transformer components: layer norm, feed-forward networks, residual connections, and how they work together.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Architecture</span>
                    <span class="tag">Components</span>
                    <span class="tag">Deep Dive</span>
                </div>
            </div>
            
            <div class="tutorial-card coming-soon">
                <div class="tutorial-icon">üéõÔ∏è</div>
                <div class="tutorial-title">
                    Multi-Head Attention Visualizer
                    <span class="coming-soon-badge">Coming Soon</span>
                </div>
                <div class="tutorial-description">
                    See how different attention heads specialize in different patterns. Interactive visualization of what each head learns during training.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Multi-Head</span>
                    <span class="tag">Visualization</span>
                    <span class="tag">Attention Patterns</span>
                </div>
            </div>
            
            <div class="tutorial-card coming-soon">
                <div class="tutorial-icon">üìà</div>
                <div class="tutorial-title">
                    Scaling Laws & Model Size
                    <span class="coming-soon-badge">Coming Soon</span>
                </div>
                <div class="tutorial-description">
                    Understand how model performance scales with parameters, compute, and data. Interactive exploration of scaling law predictions.
                </div>
                <div class="tutorial-tags">
                    <span class="tag">Scaling Laws</span>
                    <span class="tag">Model Size</span>
                    <span class="tag">Performance</span>
                </div>
            </div>
        </div>
        
        <div class="footer">
            <p>üìö Educational resource for understanding transformer architecture</p>
            <p>Built with interactive visualizations and real-world examples</p>
            <a href="https://github.com/yourusername/transformer-tutorials" class="github-link">
                ‚≠ê View on GitHub
            </a>
        </div>
    </div>
</body>
</html>
